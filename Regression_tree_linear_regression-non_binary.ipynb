{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blob\n",
    "\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/blobs_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row[:-1]\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/blobs_label.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(int(row[0]))\n",
    "print(X_training)\n",
    "print(y_training)\n",
    "        \n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/iris.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row[:-1]\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(row[-1])\n",
    "        #print(row)\n",
    "\n",
    "for i in range(len(y_training)):\n",
    "    if(y_training[i] == \"Setosa\"):\n",
    "        y_training[i] = 1\n",
    "    if(y_training[i] == \"Versicolor\"):\n",
    "        y_training[i] = 2\n",
    "    if(y_training[i] == \"Virginica\"):\n",
    "        y_training[i] = 3\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wine\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/winequality-white_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(float(row[-1]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "print(header)\n",
    "print(X_train)\n",
    "print(y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/house_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/house_price.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(float(row[0]))\n",
    "\n",
    "        \n",
    "print(len(X_training))\n",
    "print(len(y_training))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "print(X_training)\n",
    "print(y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the dataset\n",
    "def sort_f(X,y,column):\n",
    "    \n",
    "    for i in range(len(X)-1):\n",
    "        temp = i\n",
    "        for j in range(i,len(X)):\n",
    "            \n",
    "            \n",
    "\n",
    "            if(X[j][column]<X[temp][column]):\n",
    "                temp = j\n",
    "        if(temp != i):\n",
    "            tmp = X[i]\n",
    "            X[i] = X[temp]\n",
    "            X[temp] = tmp\n",
    "\n",
    "            tmp = y[i]\n",
    "            y[i] = y[temp]\n",
    "            y[temp] = tmp\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,X,feature_names,labels):\n",
    "        \n",
    "        self.X = X\n",
    "        self.num_of_nodes = 0\n",
    "        self.currentsplit = 0\n",
    "        self.split_result = 0\n",
    "        self.feature_names = feature_names #coloum names\n",
    "        self.labels = labels#y\n",
    "        self.catagories = set(labels)\n",
    "        self.nodes = []\n",
    "        self.split = 0\n",
    "        self.leaf = 0\n",
    "        self.steps = [0,0,0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,labels,X,feature_ids):\n",
    "        \n",
    "        self.split_result = 0\n",
    "        self.split = 0 #which column / which feature id\n",
    "        self.feature_ids = feature_ids\n",
    "        self.labels = labels\n",
    "        self.X = X\n",
    "        self.nodes = []\n",
    "        self.regr = 0\n",
    "        self.depth = 0\n",
    "        self.top = 0\n",
    "        self.bottom = 0\n",
    "        self.steps = [0,0,0]\n",
    "        \n",
    "        self.leaf = 0 #true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X,labels,column,bottom,top):#return splited data\n",
    "    \n",
    "    #get data in a certain range\n",
    "\n",
    "    sub_label = [labels[x] for x in range(len(labels)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "    sub_X = [X[x] for x in range(len(X)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "\n",
    "        \n",
    "    return [sub_X,sub_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(regr_type,X,y,column,dgr):\n",
    "    \n",
    "    \n",
    "    #reshape data\n",
    "    \n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "\n",
    "    \n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X,y)\n",
    "    \n",
    "    \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(regr,X,y,column,regr_type,dgr):\n",
    "    \n",
    "    \n",
    "    #reshape data\n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "    if(regr_type == 1):\n",
    "        X = PolynomialFeatures(degree=dgr).fit_transform(X)\n",
    "    predict = regr.predict(X)\n",
    "\n",
    "    difference = []\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        difference.append( (predict[i]-y[i])**2 )\n",
    "    error = sum(difference)/len(difference)\n",
    "\n",
    "  \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(i,j,column):\n",
    "    \n",
    "\n",
    " \n",
    "    n1 = [ i[0][k][column] for k in range(len(i[0])) ]\n",
    "    n2 = [ j[0][k][column] for k in range(len(j[0])) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    Ni = len(n1)\n",
    "    Nj = len(n2)\n",
    "    \n",
    "    s1i = sum(n1)/Ni\n",
    "    s1j = sum(n2)/Nj\n",
    "    \n",
    "    s2i = sum([x**2 for x in n1])/Ni\n",
    "    s2j = sum([x**2 for x in n2])/Nj\n",
    "    \n",
    "    s3i = sum([x*y for x,y in zip(n1,i[1])])/Ni\n",
    "    s3j = sum([x*y for x,y in zip(n2,j[1])])/Nj\n",
    "    \n",
    "    s4i = sum(i[1])/Ni\n",
    "    s4j = sum(j[1])/Nj\n",
    "    \n",
    "    D = (s1i-s1j)**2 + (s2i-s2j)**2 + (s3i-s3j)**2 +(s4i-s4j)**2\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_distance(sliced_data,column):\n",
    "    \n",
    "    dist = 0\n",
    "    min_dist = -1\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    \n",
    "    \n",
    "    for i in range(len(sliced_data)-1):\n",
    "\n",
    "            dist = calculate_distance(sliced_data[i],sliced_data[i+1],column)\n",
    "            \n",
    "            if(min_dist == -1):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "            if(dist<min_dist):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "    \n",
    "    return index1,index2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(sliced_data,regressions,column):\n",
    "    \n",
    "   \n",
    "\n",
    "    index1,index2 = find_min_distance(sliced_data,column)\n",
    "    \n",
    "\n",
    "    sliced_data[index1][0] = sliced_data[index1][0]+sliced_data[index2][0]\n",
    "    sliced_data[index1][1] = sliced_data[index1][1]+sliced_data[index2][1]\n",
    "\n",
    "    regressions[index1] = regression(0,sliced_data[index1][0],sliced_data[index1][1],column,0)\n",
    "    \n",
    "    sliced_data.pop(index2)\n",
    "    regressions.pop(index2)\n",
    "    \n",
    "    return sliced_data,regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(X,labels,feature_ids,steps):\n",
    "    \n",
    "    step = -1\n",
    "\n",
    "    features = 0 \n",
    "    svalue = 0\n",
    "    \n",
    "    min_error = -1\n",
    "    min_sliced_data = []\n",
    "    min_regressions = []\n",
    "    min_steps = -1\n",
    "    min_column = -1\n",
    "\n",
    "    for column in feature_ids:\n",
    "\n",
    "            \n",
    "            X,labels = sort_f(X,labels,column)\n",
    "            features = [ X[j][column] for j in range(len(X)) ] \n",
    "            \n",
    "            sliced_data = []\n",
    "            regressions = []\n",
    "           \n",
    "            \n",
    "            dist = abs(features[0]-features[-1])\n",
    "            \n",
    "            \n",
    "            step = int(dist/10)\n",
    "            \n",
    "            if(step < 2):\n",
    "                step = 1\n",
    "\n",
    "                a = [2,3]\n",
    "                b = [0,1]\n",
    "                if(steps[column] > 1 ):\n",
    "                    continue\n",
    "\n",
    "            for k in range(int(features[0]),int(features[-1])+1,step): \n",
    "\n",
    "                sliced_data.append(get_features(X,labels,column,k,k+step))\n",
    "                \n",
    "                if( len(sliced_data[-1][0]) == 0):\n",
    "\n",
    "                    \n",
    "                    sliced_data.pop(-1)\n",
    "                    continue\n",
    "                regressions.append( regression( 0,sliced_data[-1][0],sliced_data[-1][1],column,0 ) )\n",
    "                \n",
    "            while(len(sliced_data)>4):\n",
    "\n",
    "                sliced_data,regressions = merge(sliced_data,regressions,column)\n",
    "                \n",
    "            \n",
    "            error = 0\n",
    "            for i in range(len(sliced_data)):\n",
    "                \n",
    "                error += calculate_error(regressions[i],sliced_data[i][0],sliced_data[i][1],column,0,0)\n",
    "            #sum the error after the split\n",
    "            #choose min\n",
    "            \n",
    "            if(min_error == -1):\n",
    "                min_sliced_data = sliced_data\n",
    "                min_regressions = regressions\n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "                min_error = error\n",
    "                continue\n",
    "                \n",
    "            if(error<min_error):\n",
    "                min_sliced_data = sliced_data\n",
    "                min_regressions = regressions\n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "    \n",
    "    #return split,split_value\n",
    "    if(min_steps < 2 and min_steps>=0):\n",
    "            steps[min_column] += 1\n",
    "    \n",
    "    return min_sliced_data,min_regressions,min_column,steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X,feature_ids,labels,leaf_size,var,depth,steps):\n",
    "       \n",
    "    \n",
    "    \n",
    "    split = 0 \n",
    "    sub_nodes = []\n",
    "    \n",
    "    \n",
    "    st = steps.copy()\n",
    "    \n",
    "    \n",
    "    split_data,split_regression,column,st = find_best_split(X,labels,feature_ids,st)\n",
    "   \n",
    "    for i,j in zip(split_data,split_regression):\n",
    "\n",
    "        \n",
    "        node = Node(i[1],i[0],feature_ids)\n",
    "        node.split = column   #column\n",
    "        \n",
    "        #split point\n",
    "       \n",
    "        node.split_result = i[0][-1][column]\n",
    "        node.depth = depth\n",
    "        node.regr = j\n",
    "        \n",
    "        node.top = i[0][-1][column]\n",
    "        node.bottom = i[0][0][column]\n",
    "        node.steps = st\n",
    " \n",
    "        \n",
    "        \n",
    "        #Ha egy bizonyos error érték alá megyünk vagy elértünk egy bizonyos elemszámot akkor a node-ot leaf-nek nyilvánítjuk\n",
    "        if(len(node.labels) <= leaf_size or calculate_error(node.regr,node.X,node.labels,split,0,3)<1):\n",
    "            node.leaf = 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            node.leaf = 0\n",
    "        sub_nodes.append(node)\n",
    "    \n",
    "\n",
    "    if(depth == 2000):\n",
    "        for i in sub_nodes:\n",
    "            i.leaf = 1\n",
    "            \n",
    "        return sub_nodes\n",
    "    \n",
    "    depth +=1\n",
    "\n",
    "    \n",
    "    leaf =  0\n",
    "    for i in sub_nodes:\n",
    "        #print(i.steps)\n",
    "        if(i.leaf == 1):\n",
    "            leaf +=1\n",
    "    #if we reach limit return nodes             \n",
    "            \n",
    "    if(leaf == len(sub_nodes)):\n",
    "\n",
    "        return sub_nodes\n",
    "    \n",
    "    else:\n",
    "        for node in sub_nodes:\n",
    "\n",
    "            if(node.leaf == 0):\n",
    "                \n",
    "                node.nodes = build_tree(node.X,node.feature_ids,node.labels,leaf_size,var,depth,node.steps)\n",
    "\n",
    "\n",
    "    return sub_nodes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialize(X,feature_names,labels,leaf_size,var,depth):\n",
    "    \n",
    "    \n",
    "    feature_ids = [x for x in range(len(feature_names))]\n",
    "    tree = Tree(X,feature_names,labels)\n",
    "    steps = []\n",
    "    for i in feature_ids:\n",
    "        steps.append(0)\n",
    "    tree.nodes = build_tree(X,feature_ids,labels,leaf_size,var,depth,steps)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = []\n",
    "times = []\n",
    "\n",
    "\n",
    "for i in all_data:\n",
    "    \n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "    start = time.time()\n",
    "    tree = inicialize(i[0],i[-1],i[2],5,i,1)\n",
    "    end = time.time()\n",
    "    forest.append(tree)\n",
    "    print(end-start)\n",
    "    times.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(node,value):\n",
    "\n",
    "    if(node.leaf == 1 ):\n",
    "       \n",
    "        p = node.regr.predict(np.array(value[node.split]).reshape((1,-1)))\n",
    "        return p\n",
    "    else:\n",
    "        \n",
    "        c=0\n",
    "        for i in node.nodes:\n",
    "\n",
    "            if (i.top>value[i.split] and i.bottom<=value[i.split]):\n",
    "\n",
    "                c+=1\n",
    "                p=predict(i,value)\n",
    "                return p\n",
    "        if(c == 0):\n",
    "\n",
    "            try:\n",
    "                p = node.regr.predict(np.array(value[node.split]).reshape((1,-1)))\n",
    "                return p\n",
    "            except:\n",
    "                return [-1]\n",
    "            p = node.regr.predict(np.array(value[node.split]).reshape((1,-1)))\n",
    "            return p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1106.63725695]), array([3.2661282]), array([630.04366401]), array([15191.60879266])]\n",
      "[6095, 60, 5762.0, 622273.8784469217]\n"
     ]
    }
   ],
   "source": [
    "#Kiszámítjuk a teszt és a training data alapján az error mértékét\n",
    "#Valamint a test adat alapján összehasonlítjuk az eredménnyel\n",
    "\n",
    "diff = []#predicted points\n",
    "difference = []\n",
    "sum_y = []\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(forest,all_data):\n",
    "\n",
    "    X_test = j[1]\n",
    "    y_test = j[3]\n",
    "    d = []\n",
    "    error = 0\n",
    "    for k in range(len(X_test)): \n",
    "\n",
    "        p = predict(i,X_test[k])\n",
    "\n",
    "        if(p == None):\n",
    "            d.append(0)\n",
    "            continue\n",
    "        #A few extreme situations appear, so I do not take them into consideration, in order to get a clear view during visualization\n",
    "        if(abs(y_test[k]-p[0])<1000 and p[0]>0):\n",
    "            error += abs(y_test[k]-p)\n",
    "            d.append(p)\n",
    "        else:\n",
    "            d.append(0)\n",
    "        \n",
    "        #print(y_test[j],p)\n",
    "        \n",
    "    sum_y.append(sum(y_test))\n",
    "    diff.append(d)\n",
    "    difference.append(error)\n",
    "\n",
    "print(difference)\n",
    "print(sum_y)\n",
    "\n",
    "\n",
    "with open(\"DataSets/difference.csv\", 'w',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    for row in difference:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "with open(\"DataSets/sum.csv\", 'w',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    for row in sum_y:\n",
    "        writer.writerow([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DataSets/times.csv\", 'w',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c8a6292cf66ce789040457b6ebf66f3ab3b90cd403744604a52a466e4391717"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
